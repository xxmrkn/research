{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\n\nimport matplotlib.pyplot as plt\nimport random\nimport copy\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.metrics import f1_score, accuracy_score\nfrom collections import defaultdict\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nimport torchvision.models as models\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nimport torchvision.transforms.functional as TF\n\nimport cv2\nimport timm\n\nfrom tqdm import tqdm\n\nimport albumentations as A\nfrom albumentations import (\n    Compose, OneOf, Normalize, CenterCrop, Resize, RandomResizedCrop, RandomCrop, HorizontalFlip, VerticalFlip, \n    RandomBrightness, RandomContrast, RandomBrightnessContrast, RandomRotate90, ShiftScaleRotate, Cutout, \n    IAAAdditiveGaussianNoise, Transpose, HueSaturationValue, CoarseDropout\n    )\nfrom albumentations.pytorch import ToTensorV2\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport logging\nimport time\nfrom contextlib import contextmanager\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"execution":{"iopub.status.busy":"2021-07-14T11:01:31.06509Z","iopub.execute_input":"2021-07-14T11:01:31.065472Z","iopub.status.idle":"2021-07-14T11:01:31.077324Z","shell.execute_reply.started":"2021-07-14T11:01:31.06544Z","shell.execute_reply":"2021-07-14T11:01:31.075563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Directly Settings","metadata":{}},{"cell_type":"code","source":"DATA_DIR = '../input/plant-pathology-2021-fgvc8/'\nTEST_DIR = DATA_DIR + 'test_images/'\nTRAIN_DIR = DATA_DIR + 'train_images/'\nTRAIN_CSV_DIR = DATA_DIR + 'train.csv'\nTEST_CSV_DIR = DATA_DIR + 'sample_submission.csv'\ntrain_df = pd.read_csv(TRAIN_CSV_DIR)\nsub_df = pd.read_csv(TEST_CSV_DIR)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:57:26.885824Z","iopub.execute_input":"2021-07-14T10:57:26.886153Z","iopub.status.idle":"2021-07-14T10:57:26.93749Z","shell.execute_reply.started":"2021-07-14T10:57:26.886115Z","shell.execute_reply":"2021-07-14T10:57:26.936527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"train_df","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:57:29.441769Z","iopub.execute_input":"2021-07-14T10:57:29.442125Z","iopub.status.idle":"2021-07-14T10:57:29.466228Z","shell.execute_reply.started":"2021-07-14T10:57:29.442086Z","shell.execute_reply":"2021-07-14T10:57:29.465459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:57:31.565127Z","iopub.execute_input":"2021-07-14T10:57:31.5655Z","iopub.status.idle":"2021-07-14T10:57:31.577003Z","shell.execute_reply.started":"2021-07-14T10:57:31.565469Z","shell.execute_reply":"2021-07-14T10:57:31.575869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#TARGET = train_df['labels'].unique()\nTARGET = ['image','healthy', 'scab frog_eye_leaf_spot complex', 'scab', 'complex',\n       'rust', 'frog_eye_leaf_spot', 'powdery_mildew',\n       'scab frog_eye_leaf_spot', 'frog_eye_leaf_spot complex',\n       'rust frog_eye_leaf_spot', 'powdery_mildew complex',\n       'rust complex']\nSUB_LABELS = ['image','labels']\n\nTARGET","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:57:33.339906Z","iopub.execute_input":"2021-07-14T10:57:33.340258Z","iopub.status.idle":"2021-07-14T10:57:33.347628Z","shell.execute_reply.started":"2021-07-14T10:57:33.340225Z","shell.execute_reply":"2021-07-14T10:57:33.346706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# One hot encoding","metadata":{}},{"cell_type":"code","source":"train_df","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:57:35.709857Z","iopub.execute_input":"2021-07-14T10:57:35.710218Z","iopub.status.idle":"2021-07-14T10:57:35.722759Z","shell.execute_reply.started":"2021-07-14T10:57:35.710183Z","shell.execute_reply":"2021-07-14T10:57:35.721717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"onehot_df = pd.get_dummies(train_df, columns=['labels'])\nonehot_df","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:57:38.054032Z","iopub.execute_input":"2021-07-14T10:57:38.054484Z","iopub.status.idle":"2021-07-14T10:57:38.101084Z","shell.execute_reply.started":"2021-07-14T10:57:38.054443Z","shell.execute_reply":"2021-07-14T10:57:38.100047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"col = onehot_df.drop('image', axis=1)#変換したラベルを取得する\ncol","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:57:40.385656Z","iopub.execute_input":"2021-07-14T10:57:40.386028Z","iopub.status.idle":"2021-07-14T10:57:40.406661Z","shell.execute_reply.started":"2021-07-14T10:57:40.385999Z","shell.execute_reply":"2021-07-14T10:57:40.405719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TARGET_COLUMNS = col.columns.values\nTARGET_COLUMNS","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:57:42.558803Z","iopub.execute_input":"2021-07-14T10:57:42.559124Z","iopub.status.idle":"2021-07-14T10:57:42.565407Z","shell.execute_reply.started":"2021-07-14T10:57:42.559093Z","shell.execute_reply":"2021-07-14T10:57:42.564395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"onehot_df[TARGET_COLUMNS].values","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:57:44.73276Z","iopub.execute_input":"2021-07-14T10:57:44.733118Z","iopub.status.idle":"2021-07-14T10:57:44.741439Z","shell.execute_reply.started":"2021-07-14T10:57:44.733085Z","shell.execute_reply":"2021-07-14T10:57:44.74025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"onehot_df.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:57:46.305006Z","iopub.execute_input":"2021-07-14T10:57:46.305643Z","iopub.status.idle":"2021-07-14T10:57:46.312633Z","shell.execute_reply.started":"2021-07-14T10:57:46.305599Z","shell.execute_reply":"2021-07-14T10:57:46.311688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"CFG = {\n    'model_arch': 'efficientnet_b4',\n    'img_size': 320,\n    'epochs': 3,\n    'lr': 5e-4,\n}\n\nTARGET = ['image','healthy', 'scab frog_eye_leaf_spot complex', 'scab', 'complex',\n       'rust', 'frog_eye_leaf_spot', 'powdery_mildew',\n       'scab frog_eye_leaf_spot', 'frog_eye_leaf_spot complex',\n       'rust frog_eye_leaf_spot', 'powdery_mildew complex',\n       'rust complex']\n\ndef seed_everything(seed=1234):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\n@contextmanager\ndef timer(name, logger=None, level=logging.DEBUG):\n    print_ = print if logger is None else lambda msg: logger.log(level, msg)\n    t0 = time.time()\n    print_(f'[{name}] start')\n    yield\n    print_(f'[{name}] done in {time.time() - t0:.0f} s')","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:57:48.653887Z","iopub.execute_input":"2021-07-14T10:57:48.654293Z","iopub.status.idle":"2021-07-14T10:57:48.662118Z","shell.execute_reply.started":"2021-07-14T10:57:48.654256Z","shell.execute_reply":"2021-07-14T10:57:48.660999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEBUG = True\nif DEBUG:\n    onehot_df = onehot_df.sample(frac = 0.01).reset_index(drop = True)\n    print(onehot_df.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:57:52.945756Z","iopub.execute_input":"2021-07-14T10:57:52.946114Z","iopub.status.idle":"2021-07-14T10:57:52.954319Z","shell.execute_reply.started":"2021-07-14T10:57:52.946083Z","shell.execute_reply":"2021-07-14T10:57:52.953098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split data","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain, valid =  train_test_split(onehot_df, test_size = 0.1)\nprint(train.shape, valid.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:57:55.783688Z","iopub.execute_input":"2021-07-14T10:57:55.784014Z","iopub.status.idle":"2021-07-14T10:57:55.790803Z","shell.execute_reply.started":"2021-07-14T10:57:55.783985Z","shell.execute_reply":"2021-07-14T10:57:55.789748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"markdown","source":"All datasets that represent a map from keys to data samples should subclass it. All subclasses should overwrite __getitem__(), supporting fetching a data sample for a given key. Subclasses could also optionally overwrite __len__(), which is expected to return the size of the dataset by many Sampler implementations and the default options of DataLoader.","metadata":{}},{"cell_type":"code","source":"#pytorchのDatasetクラスを継承したクラスを作成する\nclass TrainDataset(Dataset):\n    def __init__(self, onehot_df, transform = None): #初期化\n        self.onehot_df = onehot_df\n        self.image_names = onehot_df[\"image\"].values\n        self.labels = onehot_df[TARGET_COLUMNS].values\n        self.transform = transform\n        \n#データの長さを返す関数\n    def __len__(self):\n        return len(self.onehot_df)\n    \n#indexに対応する画像とラベルを返す関数\n    def __getitem__(self, idx):\n        image_name = self.image_names[idx] #indexに対応するimageの値\n        image_path = TRAIN_DIR + image_name #indexに対応するデータのパス\n        image = cv2.imread(image_path) #画像読み込み\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) #BGR→RGB\n        #label = self.labels[idx] #indexに対応するラベル\n        label = torch.tensor(self.labels[idx]).float()\n        if self.transform: #前処理ある場合\n            augmented = self.transform(image=image)\n            image = augmented['image']\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:57:58.446954Z","iopub.execute_input":"2021-07-14T10:57:58.447329Z","iopub.status.idle":"2021-07-14T10:57:58.456112Z","shell.execute_reply.started":"2021-07-14T10:57:58.447298Z","shell.execute_reply":"2021-07-14T10:57:58.455004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transform","metadata":{}},{"cell_type":"code","source":"def get_transforms(*,data):\n    \n    if data == 'train':\n        return Compose([\n            A.Resize(CFG['img_size'], CFG['img_size']),\n            A.RandomResizedCrop(CFG['img_size'], CFG['img_size']),\n            A.HorizontalFlip(p=0.5),\n            A.ShiftScaleRotate(p=0.5),\n                        A.RandomBrightnessContrast(p=0.5),\n\n            A.Normalize(),\n            ToTensorV2(),\n        ])\n    elif data == 'valid':\n        return Compose([\n            Resize(CFG['img_size'], CFG['img_size']),\n            Normalize(),\n            ToTensorV2(),\n        ])","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:58:05.109663Z","iopub.execute_input":"2021-07-14T10:58:05.109984Z","iopub.status.idle":"2021-07-14T10:58:05.115847Z","shell.execute_reply.started":"2021-07-14T10:58:05.109954Z","shell.execute_reply":"2021-07-14T10:58:05.11497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 上で作成したデータセットクラスを呼び出す\ntrain_dataset = TrainDataset(onehot_df, transform = get_transforms(data = 'train'))\n# データセットクラスによって取り出されるデータをbatch数でまとめる\ntrain_loader = DataLoader(train_dataset, batch_size = 32, shuffle = True, num_workers = 2, drop_last = True)\ntrain_dataset[0]","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:58:08.602092Z","iopub.execute_input":"2021-07-14T10:58:08.602471Z","iopub.status.idle":"2021-07-14T10:58:08.860234Z","shell.execute_reply.started":"2021-07-14T10:58:08.602441Z","shell.execute_reply":"2021-07-14T10:58:08.859298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_dataset = TrainDataset(onehot_df, transform = get_transforms(data = 'valid'))\nvalid_loader = DataLoader(valid_dataset, batch_size = 32, shuffle = False, num_workers = 2)\nvalid_dataset[0]","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:58:11.719323Z","iopub.execute_input":"2021-07-14T10:58:11.71966Z","iopub.status.idle":"2021-07-14T10:58:11.849505Z","shell.execute_reply.started":"2021-07-14T10:58:11.719625Z","shell.execute_reply":"2021-07-14T10:58:11.848663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataloaders_dict = {\n    'train': train_loader, \n    'valid': valid_loader\n}","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:58:14.758118Z","iopub.execute_input":"2021-07-14T10:58:14.758554Z","iopub.status.idle":"2021-07-14T10:58:14.765065Z","shell.execute_reply.started":"2021-07-14T10:58:14.758524Z","shell.execute_reply":"2021-07-14T10:58:14.76404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_iterator = iter(dataloaders_dict['train'])\nimages, labels = next(batch_iterator)\nprint(images.size())\nprint(labels.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:58:17.579015Z","iopub.execute_input":"2021-07-14T10:58:17.579376Z","iopub.status.idle":"2021-07-14T10:58:25.513291Z","shell.execute_reply.started":"2021-07-14T10:58:17.579344Z","shell.execute_reply":"2021-07-14T10:58:25.512191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(5):\n    image, label = train_dataset[i]\n    plt.imshow(image[0])\n    plt.title(f'label: {label}')\n    plt.show() ","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:58:29.194935Z","iopub.execute_input":"2021-07-14T10:58:29.195372Z","iopub.status.idle":"2021-07-14T10:58:32.158222Z","shell.execute_reply.started":"2021-07-14T10:58:29.19533Z","shell.execute_reply":"2021-07-14T10:58:32.157351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create model","metadata":{}},{"cell_type":"code","source":"class EfficientNetB4(nn.Module):\n    \"\"\"\n        Base class for all neural network modules.\n        Your models should also subclass this class.\n        Modules can also contain other Modules, allowing to nest them in a tree structure.\n        You can assign the submodules as regular attributes:\n    \"\"\"\n    def __init__(self):\n        super().__init__()\n        self.efficientnetb4 = timm.create_model(model_name = CFG['model_arch'],pretrained = False)\n        in_features = self.efficientnetb4.classifier.in_features\n        self.efficientnetb4.classifier = nn.Linear(in_features, len(TARGET_COLUMNS))#(input_size,output_size)\n        \n    def forward(self, x):\n        x = self.efficientnetb4(x)\n        return x\n    \nmodel = EfficientNetB4()\nmodel = model.to(DEVICE)\n\n#print(model)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:58:34.927014Z","iopub.execute_input":"2021-07-14T10:58:34.927426Z","iopub.status.idle":"2021-07-14T10:58:39.731067Z","shell.execute_reply.started":"2021-07-14T10:58:34.927383Z","shell.execute_reply":"2021-07-14T10:58:39.730178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"since = time.time()\nepochs = CFG['epochs']\n\nbest_model_wts = 0\nbest_acc = 0.0\n\ncriterion = nn.BCEWithLogitsLoss().to(DEVICE)\noptimizer = torch.optim.Adam(model.parameters(), lr=CFG['lr'])\n\nfor epoch in range(epochs):\n    print('Epoch {}/{}'.format(epoch+1, epochs))\n    print('-' * 10)\n    \n    for phase in ['train', 'valid']:\n        if phase == 'train':\n            model.train()  #training\n        else:\n            model.eval()   #evaluate\n\n        running_loss = 0.0\n        running_corrects = 0\n\n        # Iterate over data.\n        for inputs, labels in dataloaders_dict[phase]:\n            inputs = inputs.to(DEVICE)\n            labels = labels.to(DEVICE)\n            #print(inputs.shape)\n            #print(labels.shape)\n\n            # zero the parameter gradients\n            optimizer.zero_grad()\n\n            # forward\n            #訓練の時だけ、履歴を保持\n            with torch.set_grad_enabled(phase == 'train'):\n                outputs = model(inputs)\n                #print(outputs.shape)\n                _, preds = torch.max(outputs, 0)\n                loss = criterion(outputs, labels)\n                #print(loss.shape)\n\n                # backward + optimize only if in training phase\n                if phase == 'train':\n                    loss.backward()\n                    optimizer.step()\n\n            # statistics\n            running_loss += loss.item()*inputs.size(0)\n            running_corrects += torch.sum(preds == labels.data)\n            \n        epoch_loss = running_loss / len(dataloaders_dict[phase])\n        epoch_acc = running_corrects.double() / len(dataloaders_dict[phase])\n        \n        print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n        #running_loss += loss.item()\n        \n        # モデルをディープ・コピー\n        if phase == 'valid' and epoch_acc > best_acc:\n            best_acc = epoch_acc\n            best_model_wts = copy.deepcopy(model.state_dict())\n    print()\n            \ntime_elapsed = time.time() - since\nprint('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\nprint('Best val Acc: {:4f}'.format(best_acc))\n\n# load best model weights\n#model.load_state_dict(best_model_wts)\n\nmodel_path = 'model.pth'\ntorch.save(model.state_dict(), model_path)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T11:01:37.552983Z","iopub.execute_input":"2021-07-14T11:01:37.553353Z","iopub.status.idle":"2021-07-14T11:03:40.199296Z","shell.execute_reply.started":"2021-07-14T11:01:37.553319Z","shell.execute_reply":"2021-07-14T11:03:40.198319Z"},"trusted":true},"execution_count":null,"outputs":[]}]}