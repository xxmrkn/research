{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\nfrom sklearn.preprocessing import LabelEncoder\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nimport torchvision.models as models\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nimport torchvision.transforms.functional as TF\n\nimport PIL\nimport cv2\n\nimport timm\n\nimport albumentations as A\nfrom albumentations import (\n    Compose, OneOf, Normalize, CenterCrop, Resize, RandomResizedCrop, RandomCrop, HorizontalFlip, VerticalFlip, \n    RandomBrightness, RandomContrast, RandomBrightnessContrast, RandomRotate90, ShiftScaleRotate, Cutout, \n    IAAAdditiveGaussianNoise, Transpose, HueSaturationValue, CoarseDropout\n    )\nfrom albumentations.pytorch import ToTensorV2\n\nfrom joblib import Parallel, delayed\n\nfrom PIL import Image\nfrom PIL import ImageFile\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport logging\nimport time\nfrom contextlib import contextmanager\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:19:09.088245Z","iopub.execute_input":"2021-06-10T05:19:09.088636Z","iopub.status.idle":"2021-06-10T05:19:13.776155Z","shell.execute_reply.started":"2021-06-10T05:19:09.088555Z","shell.execute_reply":"2021-06-10T05:19:13.775156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Directly Settings","metadata":{}},{"cell_type":"code","source":"DATA_DIR = '../input/plant-pathology-2021-fgvc8/'\nTEST_DIR = DATA_DIR + 'test_images/'\nTRAIN_DIR = DATA_DIR + 'train_images/'\nTRAIN_CSV_DIR = DATA_DIR + 'train.csv'\ntrain_df = pd.read_csv(TRAIN_CSV_DIR)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:19:13.777687Z","iopub.execute_input":"2021-06-10T05:19:13.778051Z","iopub.status.idle":"2021-06-10T05:19:13.811484Z","shell.execute_reply.started":"2021-06-10T05:19:13.778017Z","shell.execute_reply":"2021-06-10T05:19:13.810756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_DIR","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"le = LabelEncoder()\nle.fit(train_df['labels'])\ntrain_df['labels'] = le.transform(train_df['labels'])\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:19:19.206484Z","iopub.execute_input":"2021-06-10T05:19:19.206889Z","iopub.status.idle":"2021-06-10T05:19:19.25284Z","shell.execute_reply.started":"2021-06-10T05:19:19.206852Z","shell.execute_reply":"2021-06-10T05:19:19.252072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['labels'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmp = train_df[\"image\"].values\ntmp","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmp2 = train_df[\"labels\"].values\ntmp2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEBUG = True\nif DEBUG:\n    train_df = train_df.sample(frac = 0.01).reset_index(drop = True)\n    print(train_df.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:19:26.759634Z","iopub.execute_input":"2021-06-10T05:19:26.759967Z","iopub.status.idle":"2021-06-10T05:19:26.766894Z","shell.execute_reply.started":"2021-06-10T05:19:26.759937Z","shell.execute_reply":"2021-06-10T05:19:26.765937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"#../input/timm-pytorch-image-models/pytorch-image-models-master/timm/models/resnest.py\nCFG = {\n    'fold_num': 5,\n    'seed': 719,\n    'model_arch': 'resnet18',\n    'img_size': 224,\n    'epochs': 3,\n    'train_bs': 32,\n    'valid_bs': 32,\n    'lr': 1e-4,\n    'num_workers': 4,\n    'accum_iter': 1,\n    'verbose_step': 1,\n    'device': 'cuda:0',\n    'used_folds':[0,2,3],\n    'used_epochs': [7,8,9],\n    'tta': 4\n}\n\n@contextmanager\ndef timer(name, logger=None, level=logging.DEBUG):\n    print_ = print if logger is None else lambda msg: logger.log(level, msg)\n    t0 = time.time()\n    print_(f'[{name}] start')\n    yield\n    print_(f'[{name}] done in {time.time() - t0:.0f} s')\n\nTARGET_COLS = ['healthy', 'scab frog_eye_leaf_spot complex', 'scab', 'complex',\n               'rust', 'frog_eye_leaf_spot', 'powdery_mildew',\n               'scab frog_eye_leaf_spot', 'frog_eye_leaf_spot complex',\n               'rust frog_eye_leaf_spot', 'powdery_mildew complex',\n               'rust complex']","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:19:32.978584Z","iopub.execute_input":"2021-06-10T05:19:32.978909Z","iopub.status.idle":"2021-06-10T05:19:32.985732Z","shell.execute_reply.started":"2021-06-10T05:19:32.978879Z","shell.execute_reply":"2021-06-10T05:19:32.984902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TARGET_COLS","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split data","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain, valid =  train_test_split(train_df, test_size = 0.1)\nprint(train.shape, valid.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:19:39.405734Z","iopub.execute_input":"2021-06-10T05:19:39.406139Z","iopub.status.idle":"2021-06-10T05:19:39.412338Z","shell.execute_reply.started":"2021-06-10T05:19:39.406057Z","shell.execute_reply":"2021-06-10T05:19:39.411325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"markdown","source":"All datasets that represent a map from keys to data samples should subclass it. All subclasses should overwrite __getitem__(), supporting fetching a data sample for a given key. Subclasses could also optionally overwrite __len__(), which is expected to return the size of the dataset by many Sampler implementations and the default options of DataLoader.","metadata":{}},{"cell_type":"markdown","source":"## CSVファイルからデータを読み込む","metadata":{}},{"cell_type":"code","source":"#pytorchのDatasetクラスを継承したクラスを作成する\nclass TrainDataset(Dataset):\n    def __init__(self, train_df, transform = None):\n        self.train_df = train_df\n        self.image_names = train_df[\"image\"].values\n        self.labels = train_df[\"labels\"].values\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.train_df)\n    \n#indexに対応する画像とラベルを返す関数\n    def __getitem__(self, idx):\n        image_name = self.image_names[idx] #indexに対応するimageの値\n        image_path = TRAIN_DIR + image_name #indexに対応するデータのパス\n        image = cv2.imread(image_path) #画像読み込み\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) #BGR→RGB\n        #label = self.labels[idx] #indexに対応するラベル\n        label = torch.tensor(self.labels[idx]).float()\n        if self.transform: #前処理ある場合\n            augmented = self.transform(image=image)\n            image = augmented['image']\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:19:44.625762Z","iopub.execute_input":"2021-06-10T05:19:44.626093Z","iopub.status.idle":"2021-06-10T05:19:44.634465Z","shell.execute_reply.started":"2021-06-10T05:19:44.626063Z","shell.execute_reply":"2021-06-10T05:19:44.633195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TestDataset(Dataset):\n    def __init__(self, train_df, transform = None):\n        self.train_df = train_df\n        self.image_names = train_df[\"image\"].values\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.train_df)\n    \n    def __getitem__(self, idx):\n        image_name = self.image_names[idx]\n        image_path = TEST_DIR + image_name\n        image = cv2.imread(image_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented['image']\n        #image = Resize(IMAGE_SIZE, IMAGE_SIZE)(image = image)[\"image\"]\n        #image = ToTensorV2()(image = image)[\"image\"]\n        return image","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:19:46.736009Z","iopub.execute_input":"2021-06-10T05:19:46.736324Z","iopub.status.idle":"2021-06-10T05:19:46.742264Z","shell.execute_reply.started":"2021-06-10T05:19:46.736294Z","shell.execute_reply":"2021-06-10T05:19:46.741464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_transforms(*,data):\n    \n    if data == 'train':\n        return Compose([\n            Resize(CFG['img_size'], CFG['img_size']),\n            RandomResizedCrop(CFG['img_size'], CFG['img_size'], scale=(0.85, 1.0)),\n            HorizontalFlip(p=0.5),\n            Normalize(\n                mean=[0.48, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])\n    elif data == 'valid':\n        return Compose([\n            Resize(CFG['img_size'], CFG['img_size']),\n            #RandomResizedCrop(600, 600, scale=(0.85, 1.0)),\n            #HorizontalFlip(p=0.5),\n            Normalize(\n                mean=[0.48, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:19:49.180627Z","iopub.execute_input":"2021-06-10T05:19:49.180951Z","iopub.status.idle":"2021-06-10T05:19:49.18726Z","shell.execute_reply.started":"2021-06-10T05:19:49.180919Z","shell.execute_reply":"2021-06-10T05:19:49.186472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = TrainDataset(train_df, transform = get_transforms(data = 'train'))\ntrain_dataset[0]","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:19:51.644594Z","iopub.execute_input":"2021-06-10T05:19:51.644915Z","iopub.status.idle":"2021-06-10T05:19:51.910018Z","shell.execute_reply.started":"2021-06-10T05:19:51.644885Z","shell.execute_reply":"2021-06-10T05:19:51.909246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(5):\n    image, label = train_dataset[i]\n    plt.imshow(image[0])\n    plt.title(f'label: {label}')\n    plt.show() ","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:19:59.425325Z","iopub.execute_input":"2021-06-10T05:19:59.425681Z","iopub.status.idle":"2021-06-10T05:20:01.009711Z","shell.execute_reply.started":"2021-06-10T05:19:59.425649Z","shell.execute_reply":"2021-06-10T05:20:01.0089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size = 16, shuffle = True, num_workers = 2, drop_last = True)\ntrain_dataset[0]","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:20:03.987934Z","iopub.execute_input":"2021-06-10T05:20:03.988247Z","iopub.status.idle":"2021-06-10T05:20:04.11817Z","shell.execute_reply.started":"2021-06-10T05:20:03.988217Z","shell.execute_reply":"2021-06-10T05:20:04.117396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_dataset = TrainDataset(train_df, transform = get_transforms(data = 'valid'))\nvalid_loader = DataLoader(valid_dataset, batch_size = 32, shuffle = False)\nvalid_dataset[0]","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:20:06.692381Z","iopub.execute_input":"2021-06-10T05:20:06.69279Z","iopub.status.idle":"2021-06-10T05:20:06.841044Z","shell.execute_reply.started":"2021-06-10T05:20:06.692756Z","shell.execute_reply":"2021-06-10T05:20:06.840179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pprint import pprint\npprint(timm.list_models(pretrained = True))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-10T05:20:09.912446Z","iopub.execute_input":"2021-06-10T05:20:09.912776Z","iopub.status.idle":"2021-06-10T05:20:09.965422Z","shell.execute_reply.started":"2021-06-10T05:20:09.912748Z","shell.execute_reply":"2021-06-10T05:20:09.939139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class EfficientNetB4(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.efficientnetb4 = timm.create_model(model_name = 'efficientnet_b4',pretrained = False)\n        n_features = self.efficientnetb4.classifier.in_features\n        self.efficientnetb4.classifier = nn.Linear(n_features, len(TARGET_COLS))\n        \n    def forward(self, x):\n        x = self.efficientnetb4(x)\n        return x\n    \nmodel = EfficientNetB4()\nmodel = model.to(DEVICE)\nprint(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:20:18.083959Z","iopub.execute_input":"2021-06-10T05:20:18.084281Z","iopub.status.idle":"2021-06-10T05:20:22.796386Z","shell.execute_reply.started":"2021-06-10T05:20:18.08425Z","shell.execute_reply":"2021-06-10T05:20:22.794946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"batchsize = 16で12個のクラスに分けたいから出力は入力と同じ[16,12]じゃないといけない\n**tensor([3., 1., 9., 9., 3., 3., 1., 1., 9., 3., 0., 9., 1., 9., 1., 9.],\n       device='cuda:0')**","metadata":{}},{"cell_type":"markdown","source":"## Target size (torch.Size([16])) must be the same as input size (torch.Size([16, 12]))\nyは**tensor([3., 1., 9., 9., 3., 3., 1., 1., 9., 3., 0., 9., 1., 9., 1., 9.]**</br>\npredは**tensor([[ 3.3222e-03, -6.3023e-02, -9.8400e-02,  5.8039e-02,  3.5130e-02,\n         -3.7843e-02,  1.0272e-01,  5.2852e-02,  8.2996e-02, -6.2220e-02,\n          1.7350e-02,  1.0375e-01],\n        [ 4.6247e-02, -1.2377e-02, -2.6026e-02, -1.2311e-02,  8.9585e-02,\n         -3.0924e-02,  3.8724e-02,  4.6246e-02, -4.5003e-02,  4.3646e-04,\n         -6.2441e-02,  1.3156e-02],\n        [-6.2680e-02,  2.9954e-02, -6.1780e-02, -4.3327e-02,  9.0033e-02,\n         -7.6068e-02,  6.6231e-02, -2.4851e-04,  1.4230e-02, -2.5715e-03,\n          2.7242e-02,  8.6976e-02],\n        [-8.5043e-02, -1.7327e-02, -5.5150e-02,  1.6316e-02,  5.3273e-02,\n         -8.4093e-02,  5.6221e-02,  2.5884e-02,  1.6135e-01, -3.7092e-03,\n          2.5990e-02,  1.5509e-01],\n        [ 2.3410e-02, -1.7971e-02,  1.9343e-03,  2.8661e-02,  1.5071e-01,\n         -5.5160e-02,  1.0588e-01,  1.3510e-01, -8.2632e-02,  2.4116e-02,\n         -2.6500e-02, -7.0092e-02],\n        [ 3.7134e-02, -2.0467e-02, -1.3438e-02, -6.4493e-03,  8.6707e-02,\n         -5.6956e-02,  8.9093e-02,  6.9034e-02, -4.7279e-02, -9.1909e-03,\n         -3.9923e-02, -2.5610e-02],\n        [ 8.2467e-03, -5.3051e-02, -5.5619e-02, -2.7187e-03,  5.5326e-02,\n         -5.7907e-02,  3.9816e-02, -2.6238e-02,  5.2140e-02, -3.8826e-02,\n         -3.4793e-03,  1.0258e-01],\n        [ 3.2859e-02, -1.4498e-02,  1.2448e-02,  1.2810e-02,  1.0626e-01,\n         -7.5030e-02,  8.7327e-02,  1.0942e-01, -5.5229e-02,  2.2528e-02,\n         -3.3347e-02, -5.8272e-02],\n        [-4.8386e-02, -1.8281e-02, -3.5381e-02, -2.1936e-02,  1.2283e-01,\n         -7.6297e-02,  6.5367e-02,  2.9805e-03,  2.9422e-02, -5.3792e-02,\n          2.4696e-03,  1.1347e-01],\n        [ 3.9974e-02, -9.4892e-03, -2.2844e-02, -3.9816e-02,  1.1815e-01,\n         -6.9634e-02,  6.7499e-02,  6.5805e-02, -9.0425e-02,  4.7688e-03,\n         -4.0652e-02, -2.0793e-02],\n        [-2.2975e+00, -1.0275e+00,  8.9758e-02,  4.4820e-02,  1.5578e-02,\n          6.4363e-01,  3.9178e-01, -6.2643e-01,  1.2151e+00,  5.8945e-01,\n          4.7740e-01,  1.2402e+00],\n        [ 2.3138e-02, -1.8476e-02, -3.9248e-03,  1.2180e-02,  1.1278e-01,\n         -6.4264e-02,  8.0766e-02,  1.0090e-01, -7.6118e-02, -3.9621e-03,\n         -3.6371e-02, -1.6388e-02],\n        [ 1.1618e-02, -6.2424e-02, -1.4368e-02, -1.5579e-02,  1.3855e-01,\n         -5.9373e-02,  5.6734e-02,  5.6160e-02, -3.5171e-02, -2.4320e-02,\n         -1.7437e-02,  6.4983e-02],\n        [ 4.6946e-02, -2.5251e-02, -3.3545e-02, -3.9220e-02,  8.5006e-02,\n         -3.9864e-02,  5.8532e-02,  7.7934e-02, -1.5106e-02,  1.3025e-02,\n         -4.7164e-02,  1.7300e-02],\n        [ 3.7800e-02, -3.4233e-04, -9.8017e-03, -5.2540e-03,  1.2891e-01,\n         -8.4462e-02,  7.8746e-02,  1.0758e-01, -6.7346e-02,  9.4944e-03,\n         -3.6443e-02, -3.8671e-02],\n        [ 6.0334e-02,  2.2638e-02, -4.2752e-02, -3.1945e-03,  7.4823e-02,\n         -7.1255e-02,  7.4871e-02,  5.8197e-02, -1.6085e-02,  1.0187e-02,\n         -4.8222e-02, -1.2406e-02]]**","metadata":{}},{"cell_type":"code","source":"with timer('training'):\n    \n    model = EfficientNetB4().to(DEVICE)\n\n    #criterion:LogisticLoss\n    criterion = nn.BCEWithLogitsLoss()\n    #optimizer:Adam\n    optimizer = torch.optim.Adam(model.parameters())\n\n    best_loss = np.inf\nfor epoch in range(10):\n        model.train()\n        for X, y in train_loader:\n            optimizer.zero_grad()\n            X = X.float().to(DEVICE)\n            y = y.float().to(DEVICE)\n            pred = model(X)\n            print(pred.shape)\n            loss = criterion(pred, y)\n            loss.backward()\n            optimizer.step()\n        model.eval()\n        valid_loss = 0\n        with torch.no_grad():\n            for X, y in valid_loader:\n                X = X.float().to(DEVICE)\n                y = y.float().to(DEVICE)\n                pred = model(X)\n                loss = criterion(pred, y)\n                valid_loss += loss.item()\n        valid_loss /= len(valid_loader)\n        print(f\"EPOCH:{epoch}, Loss:{valid_loss}\")\n        if valid_loss < best_loss:\n            best_loss = valid_loss\n            torch.save(model.state_dict(), \"MyEfficientNetb4.pth\")\n            print(\"saved\")\n","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:25:50.893671Z","iopub.execute_input":"2021-06-10T05:25:50.894019Z","iopub.status.idle":"2021-06-10T05:25:58.697659Z","shell.execute_reply.started":"2021-06-10T05:25:50.893987Z","shell.execute_reply":"2021-06-10T05:25:58.69551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = TestDataset(test_df, transform = get_transforms(data='valid'))\ntest_loader = DataLoader(test_dataset, batch_size = 32, shuffle = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit_preds = []\n\nmodel.eval()\nwith torch.no_grad():\n    for X in test_loader:\n        X = X.float().to(DEVICE)\n        submit_preds.append(model(X).sigmoid().to(\"cpu\"))\n    submit_preds = np.concatenate([p.numpy() for p in submit_preds], axis = 0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit = pd.DataFrame(submit_preds, columns = TARGET_COLUMNS)\nsubmit.head(10)","metadata":{},"execution_count":null,"outputs":[]}]}