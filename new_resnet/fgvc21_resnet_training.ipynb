{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\n\nimport matplotlib.pyplot as plt\nimport random\nimport copy\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.metrics import f1_score, accuracy_score\nfrom collections import defaultdict\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nimport torchvision.models as models\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nimport torchvision.transforms.functional as TF\n#from efficientnet_pytorch import model as enet\n\nimport cv2\nimport timm\n\nfrom tqdm import tqdm\nfrom tqdm.notebook import tqdm\n\nimport albumentations as A\nfrom albumentations import (\n    Compose, OneOf, Normalize, CenterCrop, Resize, RandomResizedCrop, RandomCrop, HorizontalFlip, VerticalFlip, \n    RandomBrightness, RandomContrast, RandomBrightnessContrast, RandomRotate90, ShiftScaleRotate, Cutout, \n    IAAAdditiveGaussianNoise, Transpose, HueSaturationValue, CoarseDropout\n    )\nfrom albumentations.pytorch import ToTensorV2\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport logging\nimport time\nfrom contextlib import contextmanager","metadata":{"execution":{"iopub.status.busy":"2021-10-05T01:15:27.318056Z","iopub.execute_input":"2021-10-05T01:15:27.318312Z","iopub.status.idle":"2021-10-05T01:15:27.331816Z","shell.execute_reply.started":"2021-10-05T01:15:27.318281Z","shell.execute_reply":"2021-10-05T01:15:27.330718Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"class CFG:\n    DATA_PATH = '../input/plant-pathology-2021-fgvc8/'\n    TEST_PATH = DATA_PATH + 'test_images/'\n    TRAIN_PATH = DATA_PATH + 'train_images/'\n    TRAIN_CSV_PATH = DATA_PATH + 'train.csv'\n    TEST_CSV_PATH = DATA_PATH + 'sample_submission.csv'\n    \n    MODEL_ARCH ='resnet101'\n    #MODEL_ARCH = 'efficientnet_b4'\n    IMG_SIZE = 224\n    EPOCH = 10\n    BATCH_SIZE = 32\n    DEBUG_SIZE = 0.1\n    RANDOM_STATE = 1234\n    CLASS_THRESHOLD = 0.4\n    DROPOUT = .4\n    LR = 5e-4\n    \n    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    #LABELS = ['healthy','complex','rust','frog_eye_leaf_spot','powdery_mildew','scab']\n    \n    N_CLASS = 12\n    LABELS_DICT = {\n    0: 'complex', \n    1: 'frog_eye_leaf_spot',\n    2: 'frog_eye_leaf_spot complex',\n    3: 'frog_eye_leaf_spot',\n    4: 'healthy', \n    5: 'powdery_mildew complex',\n    6: 'rust',\n    7: 'rust complex',\n    8: 'rust frog_eye_leaf_spot',\n    9: 'scab',\n    10: 'scab frog_eye_leaf_spot',\n    11: 'scab frog_eye_leaf_spot complex'\n    }","metadata":{"execution":{"iopub.status.busy":"2021-10-05T01:15:35.685593Z","iopub.execute_input":"2021-10-05T01:15:35.686145Z","iopub.status.idle":"2021-10-05T01:15:35.694235Z","shell.execute_reply.started":"2021-10-05T01:15:35.686091Z","shell.execute_reply":"2021-10-05T01:15:35.693581Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(CFG.TRAIN_CSV_PATH)\nsub_df = pd.read_csv(CFG.TEST_CSV_PATH)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T01:15:41.017971Z","iopub.execute_input":"2021-10-05T01:15:41.018575Z","iopub.status.idle":"2021-10-05T01:15:41.074195Z","shell.execute_reply.started":"2021-10-05T01:15:41.018527Z","shell.execute_reply":"2021-10-05T01:15:41.073507Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"train_df","metadata":{"execution":{"iopub.status.busy":"2021-10-05T01:15:43.621938Z","iopub.execute_input":"2021-10-05T01:15:43.622503Z","iopub.status.idle":"2021-10-05T01:15:43.646347Z","shell.execute_reply.started":"2021-10-05T01:15:43.622438Z","shell.execute_reply":"2021-10-05T01:15:43.645289Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"sub_df","metadata":{"execution":{"iopub.status.busy":"2021-10-05T01:15:47.525177Z","iopub.execute_input":"2021-10-05T01:15:47.525468Z","iopub.status.idle":"2021-10-05T01:15:47.535691Z","shell.execute_reply.started":"2021-10-05T01:15:47.525438Z","shell.execute_reply":"2021-10-05T01:15:47.534547Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_df['labels'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-10-05T01:15:50.407571Z","iopub.execute_input":"2021-10-05T01:15:50.407870Z","iopub.status.idle":"2021-10-05T01:15:50.424116Z","shell.execute_reply.started":"2021-10-05T01:15:50.407840Z","shell.execute_reply":"2021-10-05T01:15:50.423422Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def visualize_batch(path,image_ids, labels):\n    plt.figure(figsize=(16, 12))\n    \n    for x, (image_id, label) in enumerate(zip(image_ids, labels)):\n        plt.subplot(3, 3, x + 1)\n        image = cv2.imread(os.path.join(path, image_id))\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        plt.imshow(image)\n        plt.title(f\"Class: {label}\", fontsize=12)\n        plt.axis(\"off\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-05T01:15:53.759413Z","iopub.execute_input":"2021-10-05T01:15:53.760060Z","iopub.status.idle":"2021-10-05T01:15:53.767961Z","shell.execute_reply.started":"2021-10-05T01:15:53.760022Z","shell.execute_reply":"2021-10-05T01:15:53.766839Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"tmp_df = train_df.sample(9)\nimage_ids = tmp_df[\"image\"].values\nlabels = tmp_df[\"labels\"].values\nvisualize_batch(CFG.TRAIN_PATH,image_ids,labels)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T01:15:56.423675Z","iopub.execute_input":"2021-10-05T01:15:56.424020Z","iopub.status.idle":"2021-10-05T01:16:07.141373Z","shell.execute_reply.started":"2021-10-05T01:15:56.423984Z","shell.execute_reply":"2021-10-05T01:16:07.139691Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\n\nle.fit(train_df.labels)\ntrain_df['labels'] = le.transform(train_df.labels)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T01:17:23.285301Z","iopub.execute_input":"2021-10-05T01:17:23.285686Z","iopub.status.idle":"2021-10-05T01:17:23.300729Z","shell.execute_reply.started":"2021-10-05T01:17:23.285650Z","shell.execute_reply":"2021-10-05T01:17:23.299573Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_df","metadata":{"execution":{"iopub.status.busy":"2021-10-05T01:17:29.676793Z","iopub.execute_input":"2021-10-05T01:17:29.677146Z","iopub.status.idle":"2021-10-05T01:17:29.692073Z","shell.execute_reply.started":"2021-10-05T01:17:29.677112Z","shell.execute_reply":"2021-10-05T01:17:29.691023Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"CFG.LABELS_DICT","metadata":{"execution":{"iopub.status.busy":"2021-10-05T01:17:34.824378Z","iopub.execute_input":"2021-10-05T01:17:34.824907Z","iopub.status.idle":"2021-10-05T01:17:34.833057Z","shell.execute_reply.started":"2021-10-05T01:17:34.824861Z","shell.execute_reply":"2021-10-05T01:17:34.831984Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# One hot encoding","metadata":{}},{"cell_type":"code","source":"def seed_everything(seed=1234):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\n@contextmanager\ndef timer(name, logger=None, level=logging.DEBUG):\n    print_ = print if logger is None else lambda msg: logger.log(level, msg)\n    t0 = time.time()\n    print_(f'[{name}] start')\n    yield\n    print_(f'[{name}] done in {time.time() - t0:.0f} s')","metadata":{"execution":{"iopub.status.busy":"2021-10-05T01:18:05.818729Z","iopub.execute_input":"2021-10-05T01:18:05.819017Z","iopub.status.idle":"2021-10-05T01:18:05.826218Z","shell.execute_reply.started":"2021-10-05T01:18:05.818987Z","shell.execute_reply":"2021-10-05T01:18:05.825432Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def to_numpy(tensor):\n    \"\"\"Auxiliary function to convert tensors into numpy arrays\n    \"\"\"\n    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n","metadata":{"execution":{"iopub.status.busy":"2021-10-05T01:18:12.246569Z","iopub.execute_input":"2021-10-05T01:18:12.247045Z","iopub.status.idle":"2021-10-05T01:18:12.252990Z","shell.execute_reply.started":"2021-10-05T01:18:12.246995Z","shell.execute_reply":"2021-10-05T01:18:12.251972Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"DEBUG = False\nif DEBUG:\n    train_df2 = train_df2.sample(frac = 0.05).reset_index(drop = True)\n    print(train_df2.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T01:18:19.459694Z","iopub.execute_input":"2021-10-05T01:18:19.460021Z","iopub.status.idle":"2021-10-05T01:18:19.465525Z","shell.execute_reply.started":"2021-10-05T01:18:19.459988Z","shell.execute_reply":"2021-10-05T01:18:19.464458Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# Split data","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain, valid =  train_test_split(train_df, test_size = 0.2)\nprint(train.shape, valid.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T01:18:30.898537Z","iopub.execute_input":"2021-10-05T01:18:30.898869Z","iopub.status.idle":"2021-10-05T01:18:30.911624Z","shell.execute_reply.started":"2021-10-05T01:18:30.898838Z","shell.execute_reply":"2021-10-05T01:18:30.910587Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"markdown","source":"All datasets that represent a map from keys to data samples should subclass it. All subclasses should overwrite __getitem__(), supporting fetching a data sample for a given key. Subclasses could also optionally overwrite __len__(), which is expected to return the size of the dataset by many Sampler implementations and the default options of DataLoader.","metadata":{}},{"cell_type":"code","source":"#pytorchのDatasetクラスを継承したクラスを作成する\nclass TrainDataset(Dataset):\n    def __init__(self, df, transform = None): #初期化\n        self.df = df\n        self.image_names = df[\"image\"].values\n        self.labels = df[\"labels\"].values\n        self.transform = transform\n        \n#データの長さを返す関数\n    def __len__(self):\n        return len(self.df)\n    \n#indexに対応する画像とラベルを返す関数\n    def __getitem__(self, idx):\n        image_name = self.image_names[idx] #indexに対応するimageの値\n        image_path = CFG.TRAIN_PATH + image_name #indexに対応するデータのパス\n        image = cv2.imread(image_path) #画像読み込み\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) #BGR→RGB\n        label = self.labels[idx] #indexに対応するラベル\n        #label = torch.tensor(self.labels[idx]).float()\n        if self.transform: #前処理ある場合\n            augmented = self.transform(image=image)\n            image = augmented['image']\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2021-10-05T01:20:20.728254Z","iopub.execute_input":"2021-10-05T01:20:20.728707Z","iopub.status.idle":"2021-10-05T01:20:20.739034Z","shell.execute_reply.started":"2021-10-05T01:20:20.728628Z","shell.execute_reply":"2021-10-05T01:20:20.738070Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# Transform","metadata":{}},{"cell_type":"code","source":"def get_transforms(data):\n    \n    if data == 'train':\n        return Compose([\n            #A.Resize(CFG.IMG_SIZE, CFG.IMG_SIZE),\n            A.RandomResizedCrop(CFG.IMG_SIZE, CFG.IMG_SIZE),\n            A.HorizontalFlip(p=0.5),\n            A.ShiftScaleRotate(p=0.5),\n            A.RandomBrightnessContrast(p=0.5),\n\n            A.Normalize(),\n            ToTensorV2(),\n        ])\n    elif data == 'valid':\n        return Compose([\n            Resize(CFG.IMG_SIZE, CFG.IMG_SIZE),\n            Normalize(),\n            ToTensorV2(),\n        ])","metadata":{"execution":{"iopub.status.busy":"2021-10-05T01:20:24.979968Z","iopub.execute_input":"2021-10-05T01:20:24.981048Z","iopub.status.idle":"2021-10-05T01:20:24.988986Z","shell.execute_reply.started":"2021-10-05T01:20:24.980996Z","shell.execute_reply":"2021-10-05T01:20:24.987969Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# 上で作成したデータセットクラスを呼び出す\ntrain_dataset = TrainDataset(train, transform = get_transforms(data = 'train'))\n# データセットクラスによって取り出されるデータをbatch数でまとめる\ntrain_loader = DataLoader(train_dataset, CFG.BATCH_SIZE, shuffle = True,drop_last = True, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T01:21:47.903085Z","iopub.execute_input":"2021-10-05T01:21:47.903577Z","iopub.status.idle":"2021-10-05T01:21:47.909450Z","shell.execute_reply.started":"2021-10-05T01:21:47.903540Z","shell.execute_reply":"2021-10-05T01:21:47.908919Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"valid_dataset = TrainDataset(valid, transform = get_transforms(data = 'valid'))\nvalid_loader = DataLoader(valid_dataset, CFG.BATCH_SIZE, shuffle = False, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T01:21:50.763951Z","iopub.execute_input":"2021-10-05T01:21:50.764237Z","iopub.status.idle":"2021-10-05T01:21:50.769267Z","shell.execute_reply.started":"2021-10-05T01:21:50.764207Z","shell.execute_reply":"2021-10-05T01:21:50.768653Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"# Create model","metadata":{}},{"cell_type":"code","source":"class ResNet(nn.Module):\n    \"\"\"\n        Base class for all neural network modules.\n        Your models should also subclass this class.\n        Modules can also contain other Modules, allowing to nest them in a tree structure.\n        You can assign the submodules as regular attributes:\n    \"\"\"\n    def __init__(self):\n        super(ResNet, self).__init__()\n        self.resnet = timm.create_model(model_name = CFG.MODEL_ARCH,pretrained = False)\n        in_features = self.resnet.fc.in_features\n        self.resnet.fc = nn.Linear(in_features, CFG.N_CLASS)#(input_size,output_size)\n        \n    def forward(self, x):\n        x = self.resnet(x)\n        return x\n    \nmodel = ResNet()\n#print(in_features)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T01:23:03.506736Z","iopub.execute_input":"2021-10-05T01:23:03.507057Z","iopub.status.idle":"2021-10-05T01:23:04.445155Z","shell.execute_reply.started":"2021-10-05T01:23:03.507025Z","shell.execute_reply":"2021-10-05T01:23:04.444511Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"def train_model(datasets, dataloaders, model, criterion, optimizer, scheduler, num_epochs, device):\n    since = time.time()\n    \n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    \n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n        print('-' * 10)\n        \n        for phase in ['train', 'valid']:\n            if phase == 'train':\n                model.train()\n            else:\n                model.eval()\n                \n            running_loss = 0.0\n            running_corrects = 0.0\n            \n            stream = tqdm(dataloaders[phase])\n            for batch ,(inputs, labels) in enumerate(stream, start=1):\n                inputs = inputs.to(CFG.DEVICE)\n                labels = labels.to(CFG.DEVICE)\n               \n                # Zero out the grads\n                optimizer.zero_grad()\n                \n                # Forward\n                # Track history in train mode\n                with torch.set_grad_enabled(phase == 'train'):\n                    model = model.to(CFG.DEVICE)\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1) \n                    loss = criterion(outputs, labels)\n                    \n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n                \n                # Statistics\n                running_loss += loss.item()*inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n            \n            if phase == 'train':\n                scheduler.step()\n                \n            epoch_loss = running_loss / len(datasets[phase])\n            epoch_acc = running_corrects.double() / len(datasets[phase])\n            \n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n            \n            if phase == 'valid' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n        \n        print()\n    \n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:.4f}'.format(best_acc))\n    \n    model.load_state_dict(best_model_wts)\n    \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datasets = {'train': train_dataset,\n            'valid': valid_dataset}\n\ndataloaders = {'train': train_loader,\n               'valid': valid_loader}\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=0.001)\ncriterion = nn.CrossEntropyLoss()\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\nnum_epochs = 10","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path = 'resnet_model.pt'\ntorch.save(model.state_dict(), model_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}